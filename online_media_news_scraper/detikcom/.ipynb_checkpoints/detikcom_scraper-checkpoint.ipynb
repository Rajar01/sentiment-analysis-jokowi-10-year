{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5771af3f-2149-4422-9335-0ba7d84205f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object Locator can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m browser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m page\u001b[38;5;241m.\u001b[39mgoto(url)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m page\u001b[38;5;241m.\u001b[39mwait_for_load_state()\n\u001b[0;32m---> 21\u001b[0m article_selectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m get_all_articles_in_current_page(page)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(article_selectors)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m browser\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m, in \u001b[0;36mget_all_articles_in_current_page\u001b[0;34m(page)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_articles_in_current_page\u001b[39m(page):\n\u001b[0;32m---> 10\u001b[0m     article_selectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m page\u001b[38;5;241m.\u001b[39mlocator(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxpath=//div[contains(@class, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist-content\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)]/article[contains(@class, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist-content__item\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m article_selectors\u001b[38;5;241m.\u001b[39mwait_for_load_state(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m article_selectors\n",
      "\u001b[0;31mTypeError\u001b[0m: object Locator can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "# Global variabel\n",
    "url = 'https://www.detik.com/search/searchnews?query=jokowi&page=1&result_type=relevansi&fromdatex=20/10/2014&todatex=20/10/2024'\n",
    "total_visited_articles_in_current_page = 0\n",
    "\n",
    "async def get_all_articles_in_current_page(page):\n",
    "    article_selectors = await page.locator('xpath=//div[contains(@class, \"list-content\")]/article[contains(@class, \"list-content__item\")]')\n",
    "    await article_selectors.wait_for_load_state(\"load\")\n",
    "    return article_selectors\n",
    "    \n",
    "async def main():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.firefox.launch()\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url)\n",
    "        await page.wait_for_load_state()\n",
    "\n",
    "        article_selectors = await get_all_articles_in_current_page(page)\n",
    "        print(article_selectors)\n",
    "        \n",
    "        await browser.close()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f9fae3-c72c-4c1c-86b4-a5f69e8418e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"889f4175-ef2d-40dc-ad70-3226cc933935\", element=\"1ab514c0-a0b6-477d-8587-4f23a9cf0b37\")>\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "from queue import Queue\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os.path\n",
    "\n",
    "# Global variabel\n",
    "url = 'https://www.detik.com/search/searchnews?query=jokowi&page=1&result_type=relevansi&fromdatex=20/10/2014&todatex=20/10/2024'\n",
    "\n",
    "def get_all_articles_in_current_page():\n",
    "    articles_htmls = WebDriverWait(browser, 5).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \n",
    "            '//div[contains(@class, \"list-content\")]/article[contains(@class, \"list-content__item\")]'\n",
    "        ))\n",
    "    )\n",
    "\n",
    "    return articles_htmls\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    browser = webdriver.Firefox(options=options)\n",
    "    browser.maximize_window()\n",
    "    browser.get(url)\n",
    "    \n",
    "    articles_htmls = get_all_articles_in_current_page()\n",
    "    print(articles_htmls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c7f7c003-721a-4f53-aa81-a92dca916719",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 66\u001b[0m\n\u001b[1;32m     62\u001b[0m element \u001b[38;5;241m=\u001b[39m WebDriverWait(browser, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[1;32m     63\u001b[0m     EC\u001b[38;5;241m.\u001b[39mpresence_of_element_located((By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//div[@class=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlist-content\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     65\u001b[0m articles_htmls \u001b[38;5;241m=\u001b[39m browser\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//h3[@class=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedia__title\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]/a[@class=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedia__link\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m article_html \u001b[38;5;241m=\u001b[39m \u001b[43marticles_htmls\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvisited_article_in_current_page\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     68\u001b[0m article_html\u001b[38;5;241m.\u001b[39mlocation_once_scrolled_into_view\n\u001b[1;32m     69\u001b[0m scroll_origin \u001b[38;5;241m=\u001b[39m ScrollOrigin\u001b[38;5;241m.\u001b[39mfrom_element(article_html)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin\n",
    "\n",
    "from queue import Queue\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os.path\n",
    "\n",
    "news_array = np.array([])\n",
    "visited_article_in_current_page = 11\n",
    "visited_page = 0\n",
    "visited_article = 0\n",
    "article_to_visit_queues = Queue()\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "browser.maximize_window()\n",
    "browser.get('https://www.detik.com/search/searchall?query=jokowi&page=1&result_type=relevansi')\n",
    "\n",
    "try:\n",
    "    element = WebDriverWait(browser, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//div[@class='list-content']\"))\n",
    "    )\n",
    "\n",
    "    articles_htmls = browser.find_elements(By.XPATH, \"//h3[@class='media__title']/a[@class='media__link']\")\n",
    "    for article_html in articles_htmls:\n",
    "        article_to_visit_queues.put(article_html)\n",
    "finally:\n",
    "    time.sleep(1)\n",
    "\n",
    "try:\n",
    "    while visited_page != 1000:\n",
    "        if article_to_visit_queues.empty() == True:\n",
    "            visited_article_in_current_page = 0\n",
    "            try:\n",
    "                element = WebDriverWait(browser, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//div[contains(@class, 'pagination')]\"))\n",
    "                )\n",
    "                element.location_once_scrolled_into_view\n",
    "                next_page_button_html = browser.find_elements(By.XPATH, \"//div[contains(@class, 'pagination')]/a\")[-1]\n",
    "                ActionChains(browser).scroll_to_element(next_page_button_html).perform()\n",
    "                ActionChains(browser).move_to_element(next_page_button_html).perform()\n",
    "                ActionChains(browser).click(next_page_button_html).perform()\n",
    "    \n",
    "                element = WebDriverWait(browser, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//div[@class='list-content']\"))\n",
    "                )\n",
    "                articles_htmls = browser.find_elements(By.XPATH, \"//h3[@class='media__title']/a[@class='media__link']\")\n",
    "                for article_html in articles_htmls:\n",
    "                    article_to_visit_queues.put(article_html)\n",
    "            \n",
    "            finally:\n",
    "                time.sleep(3)\n",
    "                visited_page += 1\n",
    "    \n",
    "        try:\n",
    "            element = WebDriverWait(browser, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[@class='list-content']\"))\n",
    "            )\n",
    "            articles_htmls = browser.find_elements(By.XPATH, \"//h3[@class='media__title']/a[@class='media__link']\")\n",
    "            article_html = articles_htmls[visited_article_in_current_page]\n",
    "\n",
    "            article_html.location_once_scrolled_into_view\n",
    "            scroll_origin = ScrollOrigin.from_element(article_html)\n",
    "            ActionChains(browser).scroll_from_origin(scroll_origin, 0, -100).perform()\n",
    "            ActionChains(browser).move_to_element(article_html).perform()\n",
    "            ActionChains(browser).click(article_html).perform()\n",
    "    \n",
    "            time.sleep(3)\n",
    "            \n",
    "            try:\n",
    "                element = WebDriverWait(browser, 5).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//*[@class='detail']\"))\n",
    "                )\n",
    "    \n",
    "                # Get news title\n",
    "                news_title_html = WebDriverWait(browser, 5).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//h1[contains(@class, 'detail__title')]\"))\n",
    "                )\n",
    "                news_title_html = browser.find_elements(By.XPATH, \"//h1[@class='detail__title ']\")\n",
    "    \n",
    "                if len(news_title_html) == 0:\n",
    "                    news_title_html = browser.find_elements(By.XPATH, \"//h1[@class='detail__title']\")[0]\n",
    "                else:\n",
    "                    news_title_html = news_title_html[0]\n",
    "    \n",
    "                # Get news author\n",
    "                news_author_html = browser.find_elements(By.XPATH, \"//div[@class='detail__author']\")\n",
    "    \n",
    "                if len(news_author_html) == 0:\n",
    "                    news_author_html = browser.find_elements(By.XPATH, \"//div[@class='detail']/div[2]\")[0]\n",
    "                else:\n",
    "                    news_author_html = news_author_html[0]\n",
    "    \n",
    "                # Get news publication date\n",
    "                news_publication_date_html = browser.find_elements(By.XPATH, \"//div[starts-with(@class, 'detail__date')]\")[0]\n",
    "          \n",
    "                # Get news text\n",
    "                news_text_htmls = WebDriverWait(browser, 5).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//div[starts-with(@class, 'detail__body-text')]/p\"))\n",
    "                )\n",
    "                news_text_htmls = browser.find_elements(By.XPATH, \"//div[starts-with(@class, 'detail__body-text')]/p\")\n",
    "                news_text = \"\"\n",
    "                \n",
    "                for news_text_html in news_text_htmls:\n",
    "                    news_text += \"\\n\" + news_text_html.text.replace('\\n', ' ')\n",
    "    \n",
    "                news = dict(\n",
    "                    news_title = news_title_html.text,\n",
    "                    news_author = news_author_html.text,\n",
    "                    news_publication_date = news_publication_date_html.text,\n",
    "                    news_text = news_text,\n",
    "                )\n",
    "                \n",
    "                news_array = np.append(news_array, news)\n",
    "            finally:\n",
    "                # Get back to page where the list of article showed and wait for 3 seconds\n",
    "                article_to_visit_queues.get()\n",
    "                visited_article_in_current_page += 1\n",
    "                visited_article += 1\n",
    "                time.sleep(3)\n",
    "                browser.back()\n",
    "        finally:\n",
    "            df = pd.DataFrame(news_array.tolist())\n",
    "    \n",
    "            if os.path.isfile('./detikcom-news-raw-data.csv') == True:\n",
    "                df.to_csv(\"detikcom-news-raw-data.csv\", sep='\\t', encoding='utf-8', index=False, header=False, mode='a')\n",
    "            else:\n",
    "                df.to_csv(\"detikcom-news-raw-data.csv\", sep='\\t', encoding='utf-8', index=False, header=True)\n",
    "            \n",
    "            news_array = np.array([])\n",
    "finally:\n",
    "    df_scrape_info = pd.DataFrame([{\n",
    "        'visited_page' : visited_page,\n",
    "        'visited_article': visited_article,\n",
    "    }])\n",
    "    \n",
    "    df_scrape_info.to_json('detikcom-scrape-info.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12580a3f-f634-4b8b-b398-830813a3f8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-venv",
   "language": "python",
   "name": "python-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
